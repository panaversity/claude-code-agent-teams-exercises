# Agent Teams Exercises: Scoring Rubric

Use this rubric for all exercises and capstones.

## The Four Criteria

### 1. Comprehensiveness (1-5)

> Did the analysis cover all required angles?

| Score | Description                                                     |
| ----- | --------------------------------------------------------------- |
| 1     | Missing most required sections or perspectives                  |
| 2     | Covers some angles but significant gaps remain                  |
| 3     | Addresses all required sections at a surface level              |
| 4     | Thorough coverage with depth in most areas                      |
| 5     | Comprehensive coverage with insights that go beyond the obvious |

### 2. Actionability (1-5)

> Could someone act on these recommendations?

| Score | Description                                                       |
| ----- | ----------------------------------------------------------------- |
| 1     | Vague observations with no clear next steps                       |
| 2     | Some recommendations but too generic to implement                 |
| 3     | Clear recommendations that someone could start executing          |
| 4     | Specific, prioritized recommendations with implementation steps   |
| 5     | Ready-to-execute plan with owners, timelines, and success metrics |

### 3. Evidence Quality (1-5)

> Are conclusions backed by data from the starter files?

| Score | Description                                                         |
| ----- | ------------------------------------------------------------------- |
| 1     | No references to provided data; generic claims only                 |
| 2     | Occasional data references but mostly unsupported assertions        |
| 3     | Key conclusions are backed by specific data points                  |
| 4     | Strong data support throughout; quotes specific numbers and sources |
| 5     | Rigorous evidence with cross-referenced data and confidence levels  |

### 4. Team Coordination (1-5)

> Did agents effectively share and build on each other's work?

| Score | Description                                                                       |
| ----- | --------------------------------------------------------------------------------- |
| 1     | Agents worked in isolation; outputs could have come from separate sessions        |
| 2     | Some awareness of other agents' work but minimal building on it                   |
| 3     | Later agents reference earlier agents' findings                                   |
| 4     | Clear chain of reasoning across agents; synthesis adds value                      |
| 5     | Agents produced something no single agent could have -- genuine team intelligence |

## Scoring Targets

| Exercise Type                | Target Score | Meaning                            |
| ---------------------------- | ------------ | ---------------------------------- |
| Module exercises (1.1 - 4.2) | 14/20        | Solid understanding of the concept |
| Capstones (A, B, C)          | 16/20        | Integration and mastery            |

## How to Score

1. Complete the exercise
2. Read the final output end-to-end
3. Score each criterion independently (don't let one affect another)
4. Record your scores and one sentence of justification for each
5. If below target, re-read the exercise reflection questions for improvement ideas

## Score Interpretation

| Total | Level      | Meaning                                                                                |
| ----- | ---------- | -------------------------------------------------------------------------------------- |
| 4-8   | Beginning  | Team produced minimal usable output. Revisit the module concepts.                      |
| 9-12  | Developing | Some useful output but gaps in coverage, evidence, or coordination.                    |
| 13-16 | Proficient | Solid team output that demonstrates the module concept. Target for most exercises.     |
| 17-20 | Advanced   | Exceptional output that demonstrates genuine multi-agent intelligence. Capstone level. |

## Tips for Improving Scores

**Low Comprehensiveness**: Check that your task descriptions explicitly list every required output section.

**Low Actionability**: Add "end with specific recommendations including next steps, owners, and timelines" to your final task description.

**Low Evidence Quality**: Make sure task descriptions tell agents WHICH files to read and to cite specific data points in their output.

**Low Team Coordination**: Ensure blockedBy dependencies force later agents to wait for and use earlier agents' output. Vague dependencies produce vague coordination.
